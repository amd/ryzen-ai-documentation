#############################################
Model Performance Tuning in Ryzen AI Software
#############################################

This page provides some of the techniques to improve CNN model performance when deploying on the NPU.

1. Enabling Compiler Optimization
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Ryzen AI software uses a ``vaip_config.json`` file to configure the Vitis AI Execution Provider. 

For CNN-based models, configuration ``opt_level`` can be used to enable advanced compiler optimization, which can improve model running efficiency on the NPU


.. code-block:: 

    "xcompilerAttrs": {
        ....
        ....
        "opt_level" : {
            "intValue" : 0
        },



The default value of ``opt_level`` is 0, which does not enable any compiler optimization. Set this to 1,2, or 3 to enable increasing levels of compiler optimizations, such as data-movement optimization, control path optimization, and operator fusion. 

- 0 (default): No advanced compiler optimization
- 1: Enable data movement optimization
- 2: Enable data movement and a certain control path optimization 
- 3: Enable data movement, control path, and operator fusion optimization


2. NPU subgraph control (experimental)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Ryzen AI software uses a ``vaip_config.json`` file to configure the Vitis AI Execution Provider. 

For CNN-based models, configuration ``dpu_subgraph_num`` limits the maximum number of NPU subgraphs that can be created from the model compilation. The final, actual number of NPU subgraphs running on the NPU can be observed during the model run as follows: 

.. code-block::

   ...
   [Vitis AI EP] No. of Subgraphs :   CPU     1    IPU     1 Actually running on IPU     1


If you see a large number of NPU subgraphs running on the NPU (but still fewer than the default ``dpu_subgraph_num:intValue=32``), you can try setting ``dpu_subgraph_num:intValue`` to a lower number. This may result in fewer NPU subgraphs, potentially alleviating slow model runtime performance.


On the other hand, if the NPU subgraphs generated by the compiler exceed the default ``dpu_subgraph_num:intValue=32``, the entire model runs on the CPU. In this scenario, you can try setting ``dpu_subgraph_num:intValue`` to a larger number, which allows more NPU subgraphs to run on the NPU, thus saving CPU power. However, this might lead to slower performance due to the increased number of NPU subgraphs.

.. code-block::

    "xcompilerAttrs": {
     .....
     "dpu_subgraph_num" : {
     "intValue" : 32
     },


This configuration can only be used as an experimental trial.


..

.. note::

In this documentation, "NPU" is used in descriptions, while "IPU" is retained in the tool's language, code, screenshots, and commands. This intentional distinction aligns with existing tool references and does not affect functionality. Avoid making replacements in the code.

  ------------

  #####################################
  License
  #####################################

  Ryzen AI is licensed under MIT License. Refer to the LICENSE file for the full license text and copyright notice.

    
